# ğŸ¤– Chat-IA

Un chat inteligente que se comunica con un modelo LLM local para responder preguntas en tiempo real, vÃ­a texto o voz. AdemÃ¡s, permite analizar documentos PDF para realizar consultas sobre su contenido.

## ğŸ› ï¸ TecnologÃ­as utilizadas

- **Node.js**  
- **Express.js**
- **JavaScript**
- **HTML + CSS**
- **Python (para transcripciÃ³n de audio con Whisper)**

## âš™ï¸ ConfiguraciÃ³n

Antes de ejecutar el proyecto, debÃ©s configurar las siguientes variables de entorno:

```bash
MODEL_URL=http://localhost:11434/api/chat
MODEL_NAME=qwen3:30b
```
Asegurate de que el modelo LLM estÃ© corriendo localmente en esa URL antes de iniciar la app.

## ğŸ”‘ Funcionalidades

ğŸ’¬ Chat por texto: interactuÃ¡ con el modelo como si fuera una conversaciÃ³n normal.

ğŸ¤ Entrada por voz: grabÃ¡ tu pregunta por micrÃ³fono, el sistema la transcribe y responde.

ğŸ“„ AnÃ¡lisis de PDF: subÃ­ un archivo PDF y hacÃ© preguntas sobre su contenido.

ğŸ§  Contexto persistente: las conversaciones pueden mantener un historial para que el modelo recuerde.

ğŸ§° Formato de respuestas mejorado: el cÃ³digo es resaltado, las respuestas son limpias y legibles.

## â–¶ï¸ InstalaciÃ³n y ejecuciÃ³n
1. Clonar el repositorio
```
git clone https://github.com/Makofig/chat-ia.git
cd chat-ia
```
2. Instalar dependencias Node.js
```
npm install
```
3. Instalar dependencias de Python
```
pip install -r requirements.txt
```
4. Iniciar la aplicaciÃ³n
```
npm start
```

## ğŸ§ª Requisitos adicionales

Whisper debe estar instalado correctamente para procesar audio.
El modelo debe estar disponible en la URL especificada (ej. Ollama, LM Studio, etc).

## Author 
Desarrollado por Aquino Marcos [Makofig] â€” Proyecto en evoluciÃ³n constante ğŸš€

## ğŸ“„ Licencia
Este proyecto estÃ¡ licenciado bajo la Licencia Apache 2.0.